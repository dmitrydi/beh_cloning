{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras as K\n",
    "import tensorflow as tf\n",
    "import os, json\n",
    "from scipy import misc\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_builder import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DATA_PATH = './data/simulator_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = pd.read_csv(os.path.join(IMAGE_DATA_PATH, 'track_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32021 entries, 0 to 32020\n",
      "Data columns (total 7 columns):\n",
      "center      32021 non-null object\n",
      "left        32021 non-null object\n",
      "right       32021 non-null object\n",
      "steering    32021 non-null float64\n",
      "throttle    32021 non-null float64\n",
      "brake       32021 non-null float64\n",
      "speed       32021 non-null float64\n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "image_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "      <th>brake</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/simulator_data/track/run2/IMG/center_2018...</td>\n",
       "      <td>data/simulator_data/track/run2/IMG/left_2018_0...</td>\n",
       "      <td>data/simulator_data/track/run2/IMG/right_2018_...</td>\n",
       "      <td>-0.064378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.19027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/simulator_data/track/run2/IMG/center_2018...</td>\n",
       "      <td>data/simulator_data/track/run2/IMG/left_2018_0...</td>\n",
       "      <td>data/simulator_data/track/run2/IMG/right_2018_...</td>\n",
       "      <td>-0.064378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.19024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/simulator_data/track/run2/IMG/center_2018...</td>\n",
       "      <td>data/simulator_data/track/run2/IMG/left_2018_0...</td>\n",
       "      <td>data/simulator_data/track/run2/IMG/right_2018_...</td>\n",
       "      <td>-0.064378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.19022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/simulator_data/track/run2/IMG/center_2018...</td>\n",
       "      <td>data/simulator_data/track/run2/IMG/left_2018_0...</td>\n",
       "      <td>data/simulator_data/track/run2/IMG/right_2018_...</td>\n",
       "      <td>-0.064378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.19008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/simulator_data/track/run2/IMG/center_2018...</td>\n",
       "      <td>data/simulator_data/track/run2/IMG/left_2018_0...</td>\n",
       "      <td>data/simulator_data/track/run2/IMG/right_2018_...</td>\n",
       "      <td>-0.038627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.19044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              center  \\\n",
       "0  data/simulator_data/track/run2/IMG/center_2018...   \n",
       "1  data/simulator_data/track/run2/IMG/center_2018...   \n",
       "2  data/simulator_data/track/run2/IMG/center_2018...   \n",
       "3  data/simulator_data/track/run2/IMG/center_2018...   \n",
       "4  data/simulator_data/track/run2/IMG/center_2018...   \n",
       "\n",
       "                                                left  \\\n",
       "0  data/simulator_data/track/run2/IMG/left_2018_0...   \n",
       "1  data/simulator_data/track/run2/IMG/left_2018_0...   \n",
       "2  data/simulator_data/track/run2/IMG/left_2018_0...   \n",
       "3  data/simulator_data/track/run2/IMG/left_2018_0...   \n",
       "4  data/simulator_data/track/run2/IMG/left_2018_0...   \n",
       "\n",
       "                                               right  steering  throttle  \\\n",
       "0  data/simulator_data/track/run2/IMG/right_2018_... -0.064378       1.0   \n",
       "1  data/simulator_data/track/run2/IMG/right_2018_... -0.064378       1.0   \n",
       "2  data/simulator_data/track/run2/IMG/right_2018_... -0.064378       1.0   \n",
       "3  data/simulator_data/track/run2/IMG/right_2018_... -0.064378       1.0   \n",
       "4  data/simulator_data/track/run2/IMG/right_2018_... -0.038627       1.0   \n",
       "\n",
       "   brake     speed  \n",
       "0    0.0  30.19027  \n",
       "1    0.0  30.19024  \n",
       "2    0.0  30.19022  \n",
       "3    0.0  30.19008  \n",
       "4    0.0  30.19044  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "ind_train, ind_test = train_test_split(np.array(range(len(image_data))), train_size=0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = image_data.loc[ind_train]\n",
    "test_df = image_data.loc[ind_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_img_path = os.path.join( 'data/simulator_data/track/flip_init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "values = []\n",
    "for i, row in train_df.iterrows():\n",
    "    imgname = row['center']\n",
    "    steering = row['steering']\n",
    "    imgname = imgname.strip()\n",
    "    img = cv2.imread(os.path.join(imgname))\n",
    "    img = cv2.flip(img, flipCode=1)\n",
    "    saving_name = os.path.join(flipped_img_path, os.path.split(imgname)[-1])\n",
    "    cv2.imwrite(saving_name, img)\n",
    "    filenames.append(saving_name)\n",
    "    values.append(-1*steering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_df = pd.DataFrame({'center': filenames, 'steering': values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_init_df = pd.concat([train_df, flipped_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brake</th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>speed</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51227</th>\n",
       "      <td>NaN</td>\n",
       "      <td>data/simulator_data/track/flip_init/center_201...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.085837</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51228</th>\n",
       "      <td>NaN</td>\n",
       "      <td>data/simulator_data/track/flip_init/center_201...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025751</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51229</th>\n",
       "      <td>NaN</td>\n",
       "      <td>data/simulator_data/track/flip_init/center_201...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.231760</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51230</th>\n",
       "      <td>NaN</td>\n",
       "      <td>data/simulator_data/track/flip_init/center_201...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.068670</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51231</th>\n",
       "      <td>NaN</td>\n",
       "      <td>data/simulator_data/track/flip_init/center_201...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.060086</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       brake                                             center left right  \\\n",
       "51227    NaN  data/simulator_data/track/flip_init/center_201...  NaN   NaN   \n",
       "51228    NaN  data/simulator_data/track/flip_init/center_201...  NaN   NaN   \n",
       "51229    NaN  data/simulator_data/track/flip_init/center_201...  NaN   NaN   \n",
       "51230    NaN  data/simulator_data/track/flip_init/center_201...  NaN   NaN   \n",
       "51231    NaN  data/simulator_data/track/flip_init/center_201...  NaN   NaN   \n",
       "\n",
       "       speed  steering  throttle  \n",
       "51227    NaN -0.085837       NaN  \n",
       "51228    NaN  0.025751       NaN  \n",
       "51229    NaN  0.231760       NaN  \n",
       "51230    NaN  0.068670       NaN  \n",
       "51231    NaN -0.060086       NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flipped_init_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brake</th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>speed</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/center...</td>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/left_2...</td>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/right_...</td>\n",
       "      <td>20.94395</td>\n",
       "      <td>-0.240343</td>\n",
       "      <td>0.066289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>data/simulator_data/track/run-5/IMG/center_201...</td>\n",
       "      <td>data/simulator_data/track/run-5/IMG/left_2018_...</td>\n",
       "      <td>data/simulator_data/track/run-5/IMG/right_2018...</td>\n",
       "      <td>21.90985</td>\n",
       "      <td>-0.326180</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/center...</td>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/left_2...</td>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/right_...</td>\n",
       "      <td>30.19028</td>\n",
       "      <td>0.025751</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>data/simulator_data/track/run-6/IMG/center_201...</td>\n",
       "      <td>data/simulator_data/track/run-6/IMG/left_2018_...</td>\n",
       "      <td>data/simulator_data/track/run-6/IMG/right_2018...</td>\n",
       "      <td>27.61868</td>\n",
       "      <td>0.154506</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/center...</td>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/left_2...</td>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/right_...</td>\n",
       "      <td>27.81060</td>\n",
       "      <td>0.111588</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brake                                             center  \\\n",
       "0    0.0  data/simulator_data/track/run3-back/IMG/center...   \n",
       "1    0.0  data/simulator_data/track/run-5/IMG/center_201...   \n",
       "2    0.0  data/simulator_data/track/run3-back/IMG/center...   \n",
       "3    0.0  data/simulator_data/track/run-6/IMG/center_201...   \n",
       "4    0.0  data/simulator_data/track/run3-back/IMG/center...   \n",
       "\n",
       "                                                left  \\\n",
       "0  data/simulator_data/track/run3-back/IMG/left_2...   \n",
       "1  data/simulator_data/track/run-5/IMG/left_2018_...   \n",
       "2  data/simulator_data/track/run3-back/IMG/left_2...   \n",
       "3  data/simulator_data/track/run-6/IMG/left_2018_...   \n",
       "4  data/simulator_data/track/run3-back/IMG/left_2...   \n",
       "\n",
       "                                               right     speed  steering  \\\n",
       "0  data/simulator_data/track/run3-back/IMG/right_...  20.94395 -0.240343   \n",
       "1  data/simulator_data/track/run-5/IMG/right_2018...  21.90985 -0.326180   \n",
       "2  data/simulator_data/track/run3-back/IMG/right_...  30.19028  0.025751   \n",
       "3  data/simulator_data/track/run-6/IMG/right_2018...  27.61868  0.154506   \n",
       "4  data/simulator_data/track/run3-back/IMG/right_...  27.81060  0.111588   \n",
       "\n",
       "   throttle  \n",
       "0  0.066289  \n",
       "1  0.000000  \n",
       "2  1.000000  \n",
       "3  0.000000  \n",
       "4  0.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flipped_init_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51232 entries, 0 to 51231\n",
      "Data columns (total 7 columns):\n",
      "brake       25616 non-null float64\n",
      "center      51232 non-null object\n",
      "left        25616 non-null object\n",
      "right       25616 non-null object\n",
      "speed       25616 non-null float64\n",
      "steering    51232 non-null float64\n",
      "throttle    25616 non-null float64\n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "flipped_init_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_df(samples_df_, source_path='data', data_columns = ['center'], val_column = 'steering', batch_size=4):\n",
    "# yields batches from dataframe samples_df: ['images', 'steering']\n",
    "    samples_df = samples_df_.copy()\n",
    "    num_samples = len(samples_df)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples_df)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples_df[offset:offset+batch_size]\n",
    "\n",
    "            images = None\n",
    "            angles = np.array([], dtype='float32')\n",
    "            for i, batch_sample in batch_samples.iterrows():\n",
    "                name = batch_sample[np.random.choice(data_columns, 1)].values[0]\n",
    "                name = name.strip()\n",
    "                center_image = cv2.imread(os.path.join(source_path,name))\n",
    "                if center_image is not None:\n",
    "                    center_angle = batch_sample[val_column]\n",
    "                    if images is None:\n",
    "                        images = center_image[np.newaxis]\n",
    "                    else:\n",
    "                        images = np.vstack([images, center_image[np.newaxis]])\n",
    "                    angles = np.append(angles, center_angle)\n",
    "\n",
    "            yield images, angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_generator_df(samples_df_, source_path='data', data_columns = ['center'], batch_size=4):\n",
    "# yields batches for predictions, no shuffling\n",
    "    samples_df = samples_df_.copy()\n",
    "    num_samples = len(samples_df)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples_df[offset:offset+batch_size]\n",
    "\n",
    "            images = None\n",
    "            angles = np.array([], dtype='float32')\n",
    "            for i, batch_sample in batch_samples.iterrows():\n",
    "                name = batch_sample[np.random.choice(data_columns, 1)].values[0]\n",
    "                name = name.strip()\n",
    "                center_image = cv2.imread(os.path.join(source_path,name))\n",
    "                center_angle = batch_sample['steering']\n",
    "                if images is None:\n",
    "                    images = center_image[np.newaxis]\n",
    "                else:\n",
    "                    images = np.vstack([images, center_image[np.newaxis]])\n",
    "                angles = np.append(angles, center_angle)\n",
    "\n",
    "            yield images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "train_generator = generator_df(flipped_init_df, source_path='', batch_size=BATCH_SIZE)\n",
    "val_generator = generator_df(test_df, source_path='', batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training VGG16-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVING_PATH = 'trained_weights/my_w/vgg16_center'\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = os.path.join(MODEL_SAVING_PATH, 'weights_vgg16e_center.{epoch:02d}-{val_loss:.4f}.hdf5')\n",
    "saver = ModelCheckpoint(saving_path, verbose=1, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16 = get_model('VGG16_e')\n",
    "model_vgg16.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6404/6404 [==============================] - 150s 23ms/step - loss: 0.0079 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00001: saving model to trained_weights/my_w/vgg16_center/weights_vgg16e_center.01-0.0081.hdf5\n",
      "Epoch 2/10\n",
      "6404/6404 [==============================] - 150s 23ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00002: saving model to trained_weights/my_w/vgg16_center/weights_vgg16e_center.02-0.0062.hdf5\n",
      "Epoch 3/10\n",
      "6404/6404 [==============================] - 150s 23ms/step - loss: 0.0066 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00003: saving model to trained_weights/my_w/vgg16_center/weights_vgg16e_center.03-0.0059.hdf5\n",
      "Epoch 4/10\n",
      "6404/6404 [==============================] - 150s 23ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00004: saving model to trained_weights/my_w/vgg16_center/weights_vgg16e_center.04-0.0057.hdf5\n",
      "Epoch 5/10\n",
      "6404/6404 [==============================] - 150s 23ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00005: saving model to trained_weights/my_w/vgg16_center/weights_vgg16e_center.05-0.0053.hdf5\n",
      "Epoch 6/10\n",
      "6404/6404 [==============================] - 150s 23ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00006: saving model to trained_weights/my_w/vgg16_center/weights_vgg16e_center.06-0.0051.hdf5\n",
      "Epoch 7/10\n",
      "6404/6404 [==============================] - 150s 23ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00007: saving model to trained_weights/my_w/vgg16_center/weights_vgg16e_center.07-0.0050.hdf5\n",
      "Epoch 8/10\n",
      "6404/6404 [==============================] - 150s 23ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00008: saving model to trained_weights/my_w/vgg16_center/weights_vgg16e_center.08-0.0049.hdf5\n",
      "Epoch 9/10\n",
      "6404/6404 [==============================] - 150s 23ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00009: saving model to trained_weights/my_w/vgg16_center/weights_vgg16e_center.09-0.0049.hdf5\n",
      "Epoch 10/10\n",
      "6404/6404 [==============================] - 150s 23ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00010: saving model to trained_weights/my_w/vgg16_center/weights_vgg16e_center.10-0.0048.hdf5\n"
     ]
    }
   ],
   "source": [
    "history_vgg16 = model_vgg16.fit_generator(train_generator, steps_per_epoch=len(flipped_init_df)/BATCH_SIZE, validation_data=val_generator,\n",
    "                                       validation_steps=len(test_df)/BATCH_SIZE, epochs=10, callbacks=[saver])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training NVIDIA-style model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = os.path.join(MODEL_SAVING_PATH, 'nvidia_my', 'weights_nvidia_my.{epoch:02d}-{val_loss:.4f}.hdf5')\n",
    "saver = ModelCheckpoint(saving_path, verbose=1, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nvidia = get_model('NVIDIA')\n",
    "model_nvidia.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "804/803 [==============================] - 14s 18ms/step - loss: 0.6236 - val_loss: 0.0154\n",
      "\n",
      "Epoch 00001: saving model to trained_weights/nvidia/weights_nvidia.01-0.0154.hdf5\n",
      "Epoch 2/10\n",
      "804/803 [==============================] - 14s 17ms/step - loss: 0.0098 - val_loss: 0.0135\n",
      "\n",
      "Epoch 00002: saving model to trained_weights/nvidia/weights_nvidia.02-0.0135.hdf5\n",
      "Epoch 3/10\n",
      "804/803 [==============================] - 14s 17ms/step - loss: 0.0052 - val_loss: 0.0154\n",
      "\n",
      "Epoch 00003: saving model to trained_weights/nvidia/weights_nvidia.03-0.0154.hdf5\n",
      "Epoch 4/10\n",
      "804/803 [==============================] - 14s 17ms/step - loss: 0.0032 - val_loss: 0.0142\n",
      "\n",
      "Epoch 00004: saving model to trained_weights/nvidia/weights_nvidia.04-0.0142.hdf5\n",
      "Epoch 5/10\n",
      "804/803 [==============================] - 14s 17ms/step - loss: 0.0036 - val_loss: 0.0142\n",
      "\n",
      "Epoch 00005: saving model to trained_weights/nvidia/weights_nvidia.05-0.0142.hdf5\n",
      "Epoch 6/10\n",
      "804/803 [==============================] - 14s 17ms/step - loss: 0.0038 - val_loss: 0.0144\n",
      "\n",
      "Epoch 00006: saving model to trained_weights/nvidia/weights_nvidia.06-0.0144.hdf5\n",
      "Epoch 7/10\n",
      "804/803 [==============================] - 14s 17ms/step - loss: 0.0049 - val_loss: 0.0138\n",
      "\n",
      "Epoch 00007: saving model to trained_weights/nvidia/weights_nvidia.07-0.0138.hdf5\n",
      "Epoch 8/10\n",
      "804/803 [==============================] - 14s 17ms/step - loss: 0.0078 - val_loss: 0.0140\n",
      "\n",
      "Epoch 00008: saving model to trained_weights/nvidia/weights_nvidia.08-0.0140.hdf5\n",
      "Epoch 9/10\n",
      "804/803 [==============================] - 14s 17ms/step - loss: 1932740.7785 - val_loss: 262.9875\n",
      "\n",
      "Epoch 00009: saving model to trained_weights/nvidia/weights_nvidia.09-262.9875.hdf5\n",
      "Epoch 10/10\n",
      "804/803 [==============================] - 14s 17ms/step - loss: 195.4979 - val_loss: 96.1313\n",
      "\n",
      "Epoch 00010: saving model to trained_weights/nvidia/weights_nvidia.10-96.1313.hdf5\n"
     ]
    }
   ],
   "source": [
    "history_nvidia = model_nvidia.fit_generator(train_generator, steps_per_epoch=len(train_df)/BATCH_SIZE, validation_data=val_generator,\n",
    "                                       validation_steps=len(test_df)/BATCH_SIZE, epochs=10, callbacks=[saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_vgg16.history['val_loss'])\n",
    "plt.plot(history_nvidia.history['val_loss'])\n",
    "plt.ylim((0,0.025))\n",
    "plt.legend(['vgg16', 'nvidia'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained model (for experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16.load_weights('trained_weights/vgg16_my/weights_vgg16.08-0.0037.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to use left and right images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_generator = predict_generator_df(train_df, source_path='', data_columns = ['center'], batch_size=BATCH_SIZE)\n",
    "left_generator = predict_generator_df(train_df, source_path='', data_columns=['left'], batch_size=BATCH_SIZE)\n",
    "right_generator = predict_generator_df(train_df, source_path='', data_columns=['right'], batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_predictions = model_vgg16.predict_generator(center_generator, steps=len(train_df)/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_predictions = center_predictions.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_predictions = model_vgg16.predict_generator(left_generator, steps=len(train_df)/BATCH_SIZE).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_predictions = model_vgg16.predict_generator(right_generator, steps=len(train_df)/BATCH_SIZE).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we calculate correction factors between predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_delta = np.mean(center_predictions - left_predictions)\n",
    "right_delta = np.mean(center_predictions - right_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.020963809 0.023573231\n"
     ]
    }
   ],
   "source": [
    "print(left_delta, right_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make extended dataset with all images used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_steering = train_df['steering'].values - left_delta\n",
    "right_steering = train_df['steering'].values - right_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "      <th>brake</th>\n",
       "      <th>speed</th>\n",
       "      <th>left_steering</th>\n",
       "      <th>right_steering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29269</th>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/center...</td>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/left_2...</td>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/right_...</td>\n",
       "      <td>-0.240343</td>\n",
       "      <td>0.066289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.94395</td>\n",
       "      <td>-0.219379</td>\n",
       "      <td>-0.263917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4416</th>\n",
       "      <td>data/simulator_data/track/run-5/IMG/center_201...</td>\n",
       "      <td>data/simulator_data/track/run-5/IMG/left_2018_...</td>\n",
       "      <td>data/simulator_data/track/run-5/IMG/right_2018...</td>\n",
       "      <td>-0.326180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.90985</td>\n",
       "      <td>-0.305216</td>\n",
       "      <td>-0.349754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29698</th>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/center...</td>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/left_2...</td>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/right_...</td>\n",
       "      <td>0.025751</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.19028</td>\n",
       "      <td>0.046715</td>\n",
       "      <td>0.002178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25176</th>\n",
       "      <td>data/simulator_data/track/run-6/IMG/center_201...</td>\n",
       "      <td>data/simulator_data/track/run-6/IMG/left_2018_...</td>\n",
       "      <td>data/simulator_data/track/run-6/IMG/right_2018...</td>\n",
       "      <td>0.154506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.61868</td>\n",
       "      <td>0.175470</td>\n",
       "      <td>0.130933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27055</th>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/center...</td>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/left_2...</td>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/right_...</td>\n",
       "      <td>0.111588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.81060</td>\n",
       "      <td>0.132552</td>\n",
       "      <td>0.088015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  center  \\\n",
       "29269  data/simulator_data/track/run3-back/IMG/center...   \n",
       "4416   data/simulator_data/track/run-5/IMG/center_201...   \n",
       "29698  data/simulator_data/track/run3-back/IMG/center...   \n",
       "25176  data/simulator_data/track/run-6/IMG/center_201...   \n",
       "27055  data/simulator_data/track/run3-back/IMG/center...   \n",
       "\n",
       "                                                    left  \\\n",
       "29269  data/simulator_data/track/run3-back/IMG/left_2...   \n",
       "4416   data/simulator_data/track/run-5/IMG/left_2018_...   \n",
       "29698  data/simulator_data/track/run3-back/IMG/left_2...   \n",
       "25176  data/simulator_data/track/run-6/IMG/left_2018_...   \n",
       "27055  data/simulator_data/track/run3-back/IMG/left_2...   \n",
       "\n",
       "                                                   right  steering  throttle  \\\n",
       "29269  data/simulator_data/track/run3-back/IMG/right_... -0.240343  0.066289   \n",
       "4416   data/simulator_data/track/run-5/IMG/right_2018... -0.326180  0.000000   \n",
       "29698  data/simulator_data/track/run3-back/IMG/right_...  0.025751  1.000000   \n",
       "25176  data/simulator_data/track/run-6/IMG/right_2018...  0.154506  0.000000   \n",
       "27055  data/simulator_data/track/run3-back/IMG/right_...  0.111588  0.000000   \n",
       "\n",
       "       brake     speed  left_steering  right_steering  \n",
       "29269    0.0  20.94395      -0.219379       -0.263917  \n",
       "4416     0.0  21.90985      -0.305216       -0.349754  \n",
       "29698    0.0  30.19028       0.046715        0.002178  \n",
       "25176    0.0  27.61868       0.175470        0.130933  \n",
       "27055    0.0  27.81060       0.132552        0.088015  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_ext = train_df\n",
    "train_df_ext['left_steering'] = train_df['steering'] - left_delta\n",
    "train_df_ext['right_steering'] = train_df['steering'] - right_delta\n",
    "train_df_ext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25616 entries, 29269 to 23654\n",
      "Data columns (total 9 columns):\n",
      "center            25616 non-null object\n",
      "left              25616 non-null object\n",
      "right             25616 non-null object\n",
      "steering          25616 non-null float64\n",
      "throttle          25616 non-null float64\n",
      "brake             25616 non-null float64\n",
      "speed             25616 non-null float64\n",
      "left_steering     25616 non-null float64\n",
      "right_steering    25616 non-null float64\n",
      "dtypes: float64(6), object(3)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df_ext.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76848 entries, 0 to 76847\n",
      "Data columns (total 2 columns):\n",
      "image    76848 non-null object\n",
      "value    76848 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df_joint = train_df_ext[['center', 'steering']].rename(columns={'center': 'image', 'steering': 'value'})\n",
    "train_df_joint = pd.concat([train_df_joint,\n",
    "                           train_df_ext[['left', 'left_steering']].rename(columns={'left': 'image', 'left_steering': 'value'})],\n",
    "                          ignore_index=True)\n",
    "train_df_joint = pd.concat([train_df_joint,\n",
    "                           train_df_ext[['right', 'right_steering']].rename(columns={'right': 'image', 'right_steering': 'value'})],\n",
    "                          ignore_index=True)\n",
    "train_df_joint.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/center...</td>\n",
       "      <td>-0.240343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/simulator_data/track/run-5/IMG/center_201...</td>\n",
       "      <td>-0.326180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/center...</td>\n",
       "      <td>0.025751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/simulator_data/track/run-6/IMG/center_201...</td>\n",
       "      <td>0.154506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/simulator_data/track/run3-back/IMG/center...</td>\n",
       "      <td>0.111588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image     value\n",
       "0  data/simulator_data/track/run3-back/IMG/center... -0.240343\n",
       "1  data/simulator_data/track/run-5/IMG/center_201... -0.326180\n",
       "2  data/simulator_data/track/run3-back/IMG/center...  0.025751\n",
       "3  data/simulator_data/track/run-6/IMG/center_201...  0.154506\n",
       "4  data/simulator_data/track/run3-back/IMG/center...  0.111588"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_joint.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_img_path = os.path.join( 'data/simulator_data/track/flipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "values = []\n",
    "for i, row in train_df_joint.iterrows():\n",
    "    imgname = row['image']\n",
    "    steering = row['value']\n",
    "    imgname = imgname.strip()\n",
    "    img = cv2.imread(os.path.join(imgname))\n",
    "    img = cv2.flip(img, flipCode=1)\n",
    "    saving_name = os.path.join(flipped_img_path, os.path.split(imgname)[-1])\n",
    "    cv2.imwrite(saving_name, img)\n",
    "    filenames.append(saving_name)\n",
    "    values.append(-1*steering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_df = pd.DataFrame({'image': filenames, 'value': values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153696 entries, 0 to 153695\n",
      "Data columns (total 2 columns):\n",
      "image    153696 non-null object\n",
      "value    153696 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "flipped_df = pd.concat([train_df_joint, flipped_df], ignore_index=True)\n",
    "flipped_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153691</th>\n",
       "      <td>data/simulator_data/track/flipped/right_2018_0...</td>\n",
       "      <td>-0.062264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153692</th>\n",
       "      <td>data/simulator_data/track/flipped/right_2018_0...</td>\n",
       "      <td>0.049324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153693</th>\n",
       "      <td>data/simulator_data/track/flipped/right_2018_0...</td>\n",
       "      <td>0.255333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153694</th>\n",
       "      <td>data/simulator_data/track/flipped/right_2018_0...</td>\n",
       "      <td>0.092243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153695</th>\n",
       "      <td>data/simulator_data/track/flipped/right_2018_0...</td>\n",
       "      <td>-0.036513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    image     value\n",
       "153691  data/simulator_data/track/flipped/right_2018_0... -0.062264\n",
       "153692  data/simulator_data/track/flipped/right_2018_0...  0.049324\n",
       "153693  data/simulator_data/track/flipped/right_2018_0...  0.255333\n",
       "153694  data/simulator_data/track/flipped/right_2018_0...  0.092243\n",
       "153695  data/simulator_data/track/flipped/right_2018_0... -0.036513"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flipped_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models on joint and flipped dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator_flipped = generator_df(flipped_df, source_path='', data_columns=['image'], val_column='value', batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16e_flipped = get_model('VGG16_e')\n",
    "model_vgg16e_flipped.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nvidia_flipped = get_model('NVIDIA')\n",
    "model_nvidia_flipped.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = os.path.join(MODEL_SAVING_PATH, 'vgg16_flipped_my', 'weights_vgg16_flipped_my.{epoch:02d}-{val_loss:.4f}.hdf5')\n",
    "saver_vgg = ModelCheckpoint(saving_path, verbose=1, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = os.path.join(MODEL_SAVING_PATH, 'nvidia_flipped', 'weights_nvidia_flipped.{epoch:02d}-{val_loss:.4f}.hdf5')\n",
    "saver_nvidia = ModelCheckpoint(saving_path, verbose=1, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19212/19212 [==============================] - 378s 20ms/step - loss: 0.0415 - val_loss: 0.0194\n",
      "\n",
      "Epoch 00001: saving model to trained_weights/vgg16e_flipped_my/weights_vgg16e_flipped_my.01-0.0194.hdf5\n",
      "Epoch 2/10\n",
      "19212/19212 [==============================] - 378s 20ms/step - loss: 0.0080 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00002: saving model to trained_weights/vgg16e_flipped_my/weights_vgg16e_flipped_my.02-0.0090.hdf5\n",
      "Epoch 3/10\n",
      "19212/19212 [==============================] - 378s 20ms/step - loss: 0.0058 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00003: saving model to trained_weights/vgg16e_flipped_my/weights_vgg16e_flipped_my.03-0.0070.hdf5\n",
      "Epoch 4/10\n",
      "19212/19212 [==============================] - 378s 20ms/step - loss: 0.0054 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00004: saving model to trained_weights/vgg16e_flipped_my/weights_vgg16e_flipped_my.04-0.0069.hdf5\n",
      "Epoch 5/10\n",
      "19212/19212 [==============================] - 378s 20ms/step - loss: 0.0052 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00005: saving model to trained_weights/vgg16e_flipped_my/weights_vgg16e_flipped_my.05-0.0065.hdf5\n",
      "Epoch 6/10\n",
      "19212/19212 [==============================] - 378s 20ms/step - loss: 0.0051 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00006: saving model to trained_weights/vgg16e_flipped_my/weights_vgg16e_flipped_my.06-0.0073.hdf5\n",
      "Epoch 7/10\n",
      "19212/19212 [==============================] - 377s 20ms/step - loss: 0.0050 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00007: saving model to trained_weights/vgg16e_flipped_my/weights_vgg16e_flipped_my.07-0.0063.hdf5\n",
      "Epoch 8/10\n",
      "19212/19212 [==============================] - 378s 20ms/step - loss: 0.0049 - val_loss: 0.0083\n",
      "\n",
      "Epoch 00008: saving model to trained_weights/vgg16e_flipped_my/weights_vgg16e_flipped_my.08-0.0083.hdf5\n",
      "Epoch 9/10\n",
      "19212/19212 [==============================] - 377s 20ms/step - loss: 0.0048 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00009: saving model to trained_weights/vgg16e_flipped_my/weights_vgg16e_flipped_my.09-0.0060.hdf5\n",
      "Epoch 10/10\n",
      "19212/19212 [==============================] - 378s 20ms/step - loss: 0.0048 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00010: saving model to trained_weights/vgg16e_flipped_my/weights_vgg16e_flipped_my.10-0.0061.hdf5\n"
     ]
    }
   ],
   "source": [
    "history_vgg16e_flipped = model_vgg16e.fit_generator(train_generator_flipped, steps_per_epoch=len(flipped_df)/BATCH_SIZE,\n",
    "                                     validation_data = val_generator, validation_steps=len(test_df)/BATCH_SIZE,\n",
    "                                 callbacks=[saver_vgg], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19212/19212 [==============================] - 319s 17ms/step - loss: 511.8605 - val_loss: 0.2383\n",
      "\n",
      "Epoch 00001: saving model to trained_weights/nvidia_flipped/weights_nvidia_flipped.01-0.2383.hdf5\n",
      "Epoch 2/10\n",
      "19212/19212 [==============================] - 319s 17ms/step - loss: 421.7276 - val_loss: 0.2795\n",
      "\n",
      "Epoch 00002: saving model to trained_weights/nvidia_flipped/weights_nvidia_flipped.02-0.2795.hdf5\n",
      "Epoch 3/10\n",
      "19212/19212 [==============================] - 319s 17ms/step - loss: 498.9718 - val_loss: 0.0843\n",
      "\n",
      "Epoch 00003: saving model to trained_weights/nvidia_flipped/weights_nvidia_flipped.03-0.0843.hdf5\n",
      "Epoch 4/10\n",
      "19212/19212 [==============================] - 319s 17ms/step - loss: 449.6086 - val_loss: 0.0765\n",
      "\n",
      "Epoch 00004: saving model to trained_weights/nvidia_flipped/weights_nvidia_flipped.04-0.0765.hdf5\n",
      "Epoch 5/10\n",
      "19212/19212 [==============================] - 319s 17ms/step - loss: 8468.1190 - val_loss: 0.0953\n",
      "\n",
      "Epoch 00005: saving model to trained_weights/nvidia_flipped/weights_nvidia_flipped.05-0.0953.hdf5\n",
      "Epoch 6/10\n",
      "19212/19212 [==============================] - 318s 17ms/step - loss: 1227.4394 - val_loss: 0.4933\n",
      "\n",
      "Epoch 00006: saving model to trained_weights/nvidia_flipped/weights_nvidia_flipped.06-0.4933.hdf5\n",
      "Epoch 7/10\n",
      "19212/19212 [==============================] - 318s 17ms/step - loss: 203.1196 - val_loss: 0.0697\n",
      "\n",
      "Epoch 00007: saving model to trained_weights/nvidia_flipped/weights_nvidia_flipped.07-0.0697.hdf5\n",
      "Epoch 8/10\n",
      "19212/19212 [==============================] - 317s 17ms/step - loss: 949.8269 - val_loss: 2.0558\n",
      "\n",
      "Epoch 00008: saving model to trained_weights/nvidia_flipped/weights_nvidia_flipped.08-2.0558.hdf5\n",
      "Epoch 9/10\n",
      "19212/19212 [==============================] - 318s 17ms/step - loss: 5069.3183 - val_loss: 26.1272\n",
      "\n",
      "Epoch 00009: saving model to trained_weights/nvidia_flipped/weights_nvidia_flipped.09-26.1272.hdf5\n",
      "Epoch 10/10\n",
      "19212/19212 [==============================] - 317s 17ms/step - loss: 18277.9559 - val_loss: 0.5789\n",
      "\n",
      "Epoch 00010: saving model to trained_weights/nvidia_flipped/weights_nvidia_flipped.10-0.5789.hdf5\n"
     ]
    }
   ],
   "source": [
    "history_nvidia_flipped = model_nvidia_flipped.fit_generator(train_generator_flipped, steps_per_epoch=len(flipped_df)/BATCH_SIZE,\n",
    "                                     validation_data = val_generator, validation_steps=len(test_df)/BATCH_SIZE,\n",
    "                                 callbacks=[saver_nvidia], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('train_history', 'history_vgg16.json'), 'w') as f:\n",
    "    json.dump(history_vgg16.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('train_history', 'history_nvidia.json'), 'w') as f:\n",
    "    json.dump(history_nvidia.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('train_history', 'history_vgg16_joint.json'), 'w') as f:\n",
    "    json.dump(history_vgg16_joint.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('train_history', 'history_vgg16_flipped.json'), 'w') as f:\n",
    "    json.dump(history_vgg16_flipped.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('train_history', 'history_vgg16e_flipped.json'), 'w') as f:\n",
    "    json.dump(history_vgg16e_flipped.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('train_history', 'history_nvidia_joint.json'), 'w') as f:\n",
    "    json.dump(history_nvidia_joint.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('train_history', 'history_nvidia_flipped.json'), 'w') as f:\n",
    "    json.dump(history_nvidia_flipped.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('datasets', 'train_df.p'), 'wb') as f:\n",
    "    pickle.dump(train_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('datasets', 'train_df_joint.p'), 'wb') as f:\n",
    "    pickle.dump(train_df_joint, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('datasets', 'train_df_flipped.p'), 'wb') as f:\n",
    "    pickle.dump(flipped_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('datasets', 'test_df.p'), 'wb') as f:\n",
    "    pickle.dump(test_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
